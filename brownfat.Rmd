---
title: "brownfat"
output: html_document
---

```{r}
library(readxl)
library(dplyr)
```

Read the file:

```{r}
# the excel sheet represents NA values by "NA"
brownfat <- read_excel("./description/BrownFat.xls", na = "NA")
nrow(brownfat)
```

Check if there's any NA values:

```{r}
x <- colSums(is.na(brownfat)) # 
x[x > 0]
```

3 variables has NA values detected: Cancer_Status, Cancer_Type, and TSH. Data cleaning needed.

Notice that $4425$ out of $n=4842$ observations had no data on their `TSH`, as this ratio is too large in order for us to confidently assign the most-probable values, we will choose to exclude the variable `TSH` altogether.

```{r}
brownfat_cleaned_data <- brownfat %>% dplyr::select(-c("TSH"))
```

There are observations where both the `Cancer_Status` and `Cancer_Type` is set to NA, as we don't have domain knowledge to assign appropriate values nor is it the main focus of this research, we will simply exclude these observations.

```{r}
# determine how many obs. display such behaviour
x <- sum(is.na(brownfat$Cancer_Status) & is.na(brownfat$Cancer_Type))
paste("No. of observations w/ Cancer_Status == Cancer_Type == NA is:", x)

# exclude these obs.
brownfat_cleaned_data <- brownfat_cleaned_data %>% 
  filter(!(is.na(Cancer_Status) & is.na(Cancer_Type)))
```

Observe that since the remaining $369  - 250 = 119$ observations still having `Cancer_Type == NA` also have that `Cancer_Status == 0`, meaning they do have cancer (thus setting `Cancer_Type` to $0$ is not a valid option) and hence we can either assign values to these missing values or once again, simply remove them.

-   Option 1: We calculate the estimate probability of each category (other than $0$) based on their frequency in the given data, and then assign `NA` values using our new probability measure.

```{r}
set.seed("14")

# calculate the estimated prob. of each category (except 0, and NAs)
cancer_status_category_prob <- brownfat_cleaned_data %>%
  filter(!is.na(Cancer_Type) & Cancer_Type != 0) %>%
  count(Cancer_Type) %>% 
  mutate(probability = n / sum(n))

# function to re-assign those w/ NA values
assign_cancer_type <- function(x) {
  if (is.na(x)) {
    sample(cancer_status_category_prob$Cancer_Type, 1, 
           prob = cancer_status_category_prob$probability)
  } else {
    x
  }
}


# re-assign those w/ Cancer_Type == NA
brownfat_cleaned_data_v1 <- brownfat_cleaned_data
brownfat_cleaned_data_v1$Cancer_Type <- sapply(brownfat_cleaned_data$Cancer_Type,
                                   assign_cancer_type)
```

Why may this method be problematic? =\> We've only taking into the account the frequencies of each of these types of cancer when in reality, a multitude of other factors affect the diagnosis of single patient. (We may consider to improve this later on by also creating a prediction model)

-   Option 2: To avoid potential hazardous assumptions, we may opt to exclude these `NA` values altogether:

```{r}
brownfat_cleaned_data_v2 <- brownfat_cleaned_data %>%
  filter(!is.na(Cancer_Type))
```

## ZERO-INFLATED MODEL

Split into training and testing set.

```{r}
# convert categorical vars into factors, and rename some vars.
brownfat_cleaned_data_v2 <- brownfat_cleaned_data_v2 %>%
  mutate(Sex = as.factor(Sex),
         Diabetes = as.factor(Diabetes),
         Month = as.factor(Month),
         Season = as.factor(Season),
         Cancer_Status = as.factor(Cancer_Status),
         Cancer_Type = as.factor(Cancer_Type)) %>%
  rename(Temp_2D = `2D_Temp`,
         Temp_3D = `3D_Temp`,
         Temp_7D = `7D_Temp`,
         Temp_1M = `1M_Temp`)

# split into train and test set
set.seed(500)
samp <- sample(1:nrow(brownfat_cleaned_data_v2),
               size = floor(0.7*nrow(brownfat_cleaned_data_v2)),
               replace=FALSE)
train <- brownfat_cleaned_data_v2[samp,]
test <- brownfat_cleaned_data_v2[-samp,]
```

Libraries needed:
```{r}
require(flexplot)
require(tidyverse)
require(pscl)
```


Optional: try to downsample our training set but still be as large as test set.

```{r}
library(ROSE)
train$BrownFat <- ifelse(train$Total_vol > 0, 1, 0)
train_data_oversampled <- 
  ovun.sample(BrownFat ~ ., data = train, method = "under", N = 800)$data
```

We will transform Y to better visualize and work with it.

```{r}
train <- train %>% 
  mutate(log_vol = round(log(Total_vol+1)*10)) 
# optional if using under-sampled data
train_data_oversampled <- train_data_oversampled %>% 
  mutate(log_vol = round(log(Total_vol+1)*2)) 

# optional: get rid of any obs above some value (between those having brownfat) = 28
train_rid_obs <- train %>% filter(log_vol <= 55)

# the mult. by 2 is to keep as much unique values as possible, consider the difference:
unique(sort(round(log(train$Total_vol+1))))
unique(sort(round(log(train$Total_vol+1)*10)))
unique(sort(round(log(train_data_oversampled$Total_vol+1)*2)))
```

The difference in visualization is somewhat visible when looking at Y and the transformed Y, but both are nonetheless very much zero-inflated.
```{r}
flexplot(log_vol~1, data=train)
flexplot(Total_vol~1, data=train)
flexplot(log_vol~1, data=train_data_oversampled)
```

Let's now do the zero inflated model, consider a very simple formula as to avoid non-convergence

```{r}
mod <- zeroinfl(log_vol ~ Age + Sex + Ext_Temp + BMI + Temp_7D + Temp_3D + Temp_2D
                + Temp_1M + Diabetes + Weigth + Glycemy + LBW + Cancer_Status 
                | Age + Sex + Ext_Temp + BMI
                , data=train, dist="negbin") 
mod.step <- stats::step(mod, direction="both")
summary(mod.step)
```


Check its summary:
```{r}
summary(mod.step)
extractAIC(mod.step)
```
Observe its estimates:

```{r}
pred.test <- exp(predict(mod, 
                         newdata=test, 
                         type="response")/10)-1
actual.test <- test$Total_vol
MSPE <- sum((actual.test-pred.test)^2) / nrow(test)
MSPE

pred.train <- exp(predict(mod,
                          type="response")/10)-1
actual.train <- train$Total_vol
MSE <- sum((actual.train-pred.train)^2) / (nrow(train) - length(coef(mod)))
MSE
```

## GAMMA ZERO INFLATED

```{r}
library(glmmTMB)

zig_model <- glmmTMB(Total_vol ~ Age + Sex + Ext_Temp + Temp_3D + Temp_2D + 
    Temp_1M + Diabetes + Weigth + LBW,
                     ziformula = ~ Age + Sex + Ext_Temp + Temp_3D + Temp_2D + 
    Temp_1M + Diabetes + Weigth + LBW,
                     family = lognormal(link = "log"),
                     data = train)

```

```{r}
summary(zig_model)
```

```{r}
pred.test <- predict(zig_model, 
                         newdata=test, 
                         type="response")
actual.test <- test$Total_vol
MSPE <- sum((actual.test-pred.test)^2) / nrow(test)
MSPE

pred.train <- predict(zig_model,
                          type="response")
actual.train <- train$Total_vol
MSE <- sum((actual.train-pred.train)^2) / (nrow(train) - 20)
MSE

```


## MODEL DIAGNOSTICS

```{r}
ggplot(data=NULL, aes(x=mod$fitted.values, mod$residuals)) + 
  geom_point()

# Detect outliers using IQR (Interquartile Range)
Q1 <- quantile(mod$residuals, 0.25)
Q3 <- quantile(mod$residuals, 0.75)
IQR_val <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR_val
upper_bound <- Q3 + 1.5 * IQR_val

# Find outliers
outliers <- which(mod$residuals < lower_bound | mod$residuals > upper_bound)

cat("Number of outliers detected:", length(outliers))
```

