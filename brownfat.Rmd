---
title: "brownfat"
output: html_document
---

```{r}
library(readxl)
library(dplyr)
library(MASS)
library(MPV)
```

Read the file:

```{r}
# the excel sheet represents NA values by "NA"
brownfat <- read_excel("./description/BrownFat.xls", na = "NA")
nrow(brownfat)
```

Check if there's any NA values:

```{r}
x <- colSums(is.na(brownfat)) 
x[x > 0]
```

3 variables has NA values detected: Cancer_Status, Cancer_Type, and TSH. Data cleaning needed.

Notice that $4425$ out of $n=4842$ observations had no data on their `TSH`, as this ratio is too large in order for us to confidently assign the most-probable values, we will choose to exclude the variable `TSH` altogether.

```{r}
brownfat_cleaned_data <- brownfat %>% dplyr::select(-c("TSH"))
```

There are observations where both the `Cancer_Status` and `Cancer_Type` is set to NA, as we don't have domain knowledge to assign appropriate values nor is it the main focus of this research, we will simply exclude these observations.

```{r}
# determine how many obs. display such behaviour
x <- sum(is.na(brownfat$Cancer_Status) & is.na(brownfat$Cancer_Type))
paste("No. of observations w/ Cancer_Status == Cancer_Type == NA is:", x)

# exclude these obs.
brownfat_cleaned_data <- brownfat_cleaned_data %>% 
  filter(!(is.na(Cancer_Status) & is.na(Cancer_Type)))
```

Observe that since the remaining $369  - 250 = 119$ observations still having `Cancer_Type == NA` also have that `Cancer_Status == 0`, meaning they do have cancer (thus setting `Cancer_Type` to $0$ is not a valid option) and hence we can either assign values to these missing values or once again, simply remove them.

-   Option 1: We calculate the estimate probability of each category (other than $0$) based on their frequency in the given data, and then assign `NA` values using our new probability measure.

```{r}
set.seed("14")

# calculate the estimated prob. of each category (except 0, and NAs)
cancer_status_category_prob <- brownfat_cleaned_data %>%
  filter(!is.na(Cancer_Type) & Cancer_Type != 0) %>%
  count(Cancer_Type) %>% 
  mutate(probability = n / sum(n))

# function to re-assign those w/ NA values
assign_cancer_type <- function(x) {
  if (is.na(x)) {
    sample(cancer_status_category_prob$Cancer_Type, 1, 
           prob = cancer_status_category_prob$probability)
  } else {
    x
  }
}


# re-assign those w/ Cancer_Type == NA
brownfat_cleaned_data_v1 <- brownfat_cleaned_data
brownfat_cleaned_data_v1$Cancer_Type <- sapply(brownfat_cleaned_data$Cancer_Type,
                                   assign_cancer_type)
```

Why may this method be problematic? =\> We've only taking into the account the frequencies of each of these types of cancer when in reality, a multitude of other factors affect the diagnosis of single patient. (We may consider to improve this later on by also creating a prediction model)

-   Option 2: To avoid potential hazardous assumptions, we may opt to exclude these `NA` values altogether:

```{r}
brownfat_cleaned_data_v2 <- brownfat_cleaned_data %>%
  filter(!is.na(Cancer_Type))
```

## MODEL SELECTION

We will partition the cleaned data (version 1) into 2 equal parts: training and testing dataset.

```{r}
set.seed("15")
training_data <- brownfat_cleaned_data_v1 %>%
  slice_sample(prop = 0.5)
testing_data <- anti_join(brownfat_cleaned_data_v1, training_data)
```

We shall perform Step-wise Regression on our training data.

```{r}
fit_full <- lm(Total_vol ~ . -Id , data=training_data) # full model
fit_intercept <- lm(Total_vol ~ 1, data=training_data) # intercept model

step <- stepAIC(fit_intercept, scope=list(upper=fit_full, lower=fit_intercept),
        direction="both")
```

The selected model via Step-wise Regression is given as follows:

```{r}
summary(step)
```

To make sure our assignment of NA values for `Cancer_Type` wasn't problematic, we will also perform the same test on version 2 of the cleaned data.

```{r}
set.seed("15")
training_data_v2 <- brownfat_cleaned_data_v2 %>%
  slice_sample(prop = 0.5)
testing_data_v2 <- anti_join(brownfat_cleaned_data_v2, training_data_v2)
```

```{r}
fit_full_v2 <- lm(Total_vol ~ . -Id , data=training_data_v2) # full model
fit_intercept_v2 <- lm(Total_vol ~ 1, data=training_data_v2) # intercept model

step_v2 <- stepAIC(fit_intercept_v2, 
                scope=list(upper=fit_full_v2, lower=fit_intercept_v2),
                direction="both")
```

```{r}
summary(step_v2)
AIC(step_v2)
```

NOTE: The model trained on v1 of the cleaned data reported a better $R^2$, $R^2_{adj}$, but smaller $AIC$ than the model trained on v2 of the cleaned data.
