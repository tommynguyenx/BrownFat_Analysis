---
title: "brownfat"
output: html_document
---

```{r}
library(readxl)
library(dplyr)
library(MPV)
library(ggplot2)
library(glmnet)
library(caret)
library(tidymodels)
library(car)
```

Read the file:

```{r}
# the excel sheet represents NA values by "NA"
brownfat <- read_excel("./description/BrownFat.xls", na = "NA")
nrow(brownfat)
```

Check if there's any NA values:

```{r}
x <- colSums(is.na(brownfat)) # 
x[x > 0]
```

3 variables has NA values detected: Cancer_Status, Cancer_Type, and TSH. Data cleaning needed.

Notice that $4425$ out of $n=4842$ observations had no data on their `TSH`, as this ratio is too large in order for us to confidently assign the most-probable values, we will choose to exclude the variable `TSH` altogether.

```{r}
brownfat_cleaned_data <- brownfat %>% dplyr::select(-c("TSH"))
```

There are observations where both the `Cancer_Status` and `Cancer_Type` is set to NA, as we don't have domain knowledge to assign appropriate values nor is it the main focus of this research, we will simply exclude these observations.

```{r}
# determine how many obs. display such behaviour
x <- sum(is.na(brownfat$Cancer_Status) & is.na(brownfat$Cancer_Type))
paste("No. of observations w/ Cancer_Status == Cancer_Type == NA is:", x)

# exclude these obs.
brownfat_cleaned_data <- brownfat_cleaned_data %>% 
  filter(!(is.na(Cancer_Status) & is.na(Cancer_Type)))
```

Observe that since the remaining $369  - 250 = 119$ observations still having `Cancer_Type == NA` also have that `Cancer_Status == 0`, meaning they do have cancer (thus setting `Cancer_Type` to $0$ is not a valid option) and hence we can either assign values to these missing values or once again, simply remove them.

-   Option 1: We calculate the estimate probability of each category (other than $0$) based on their frequency in the given data, and then assign `NA` values using our new probability measure.

```{r}
set.seed("14")

# calculate the estimated prob. of each category (except 0, and NAs)
cancer_status_category_prob <- brownfat_cleaned_data %>%
  filter(!is.na(Cancer_Type) & Cancer_Type != 0) %>%
  count(Cancer_Type) %>% 
  mutate(probability = n / sum(n))

# function to re-assign those w/ NA values
assign_cancer_type <- function(x) {
  if (is.na(x)) {
    sample(cancer_status_category_prob$Cancer_Type, 1, 
           prob = cancer_status_category_prob$probability)
  } else {
    x
  }
}


# re-assign those w/ Cancer_Type == NA
brownfat_cleaned_data_v1 <- brownfat_cleaned_data
brownfat_cleaned_data_v1$Cancer_Type <- sapply(brownfat_cleaned_data$Cancer_Type,
                                   assign_cancer_type)
```

Why may this method be problematic? =\> We've only taking into the account the frequencies of each of these types of cancer when in reality, a multitude of other factors affect the diagnosis of single patient. (We may consider to improve this later on by also creating a prediction model)

-   Option 2: To avoid potential hazardous assumptions, we may opt to exclude these `NA` values altogether:

```{r}
brownfat_cleaned_data_v2 <- brownfat_cleaned_data %>%
  filter(!is.na(Cancer_Type))
```

## MODEL SELECTION - Initial Attempt

We are to do cross-validation, i.e. divide our data into 2 sets, training and validation, using a 70/30 split.

```{r}
# we first exclude non-important cols, i.e. Id
brownfat_cleaned_data_v2 <- brownfat_cleaned_data_v2[, -1]
# convert categorical to factors
brownfat_cleaned_data_v2$Cancer_Status <- as.factor(brownfat_cleaned_data_v2$Cancer_Status)
brownfat_cleaned_data_v2$Cancer_Type <- as.factor(brownfat_cleaned_data_v2$Cancer_Type)
brownfat_cleaned_data_v2$Season <- as.factor(brownfat_cleaned_data_v2$Season)
brownfat_cleaned_data_v2$Diabetes <- as.factor(brownfat_cleaned_data_v2$Diabetes)
brownfat_cleaned_data_v2$Sex <- as.factor(brownfat_cleaned_data_v2$Sex)
brownfat_cleaned_data_v2$Month <- as.factor(brownfat_cleaned_data_v2$Month)


set.seed(500)
brownfat.sample <- sample(1:nrow(brownfat_cleaned_data_v2),
                          floor(0.7*nrow(brownfat_cleaned_data_v2)),
                          replace = FALSE) # sample w/o replacement
brownfat.train <- brownfat_cleaned_data_v2[brownfat.sample, ] # model-building data
brownfat.test <- brownfat_cleaned_data_v2[-brownfat.sample, ] # validation data
```

We perform step-wise regression to find the fitted model to predict $Y$, i.e. `Total_vol`, using the training data set.

```{r}
fit.simple <- lm(Total_vol ~ 1, data=brownfat.train) # intercept model
fit.full <- lm(Total_vol ~ ., data=brownfat.train) # full model

fit.stepwise <- stats::step(fit.simple, scope = list(upper=fit.full, lower=fit.simple),
                     direction='both', trace=0)
```

This is the obtained model's prediction power, using step-wise regression.
```{r}
model <- summary(fit.stepwise)
n <- nrow(brownfat.train)
p_prime <- length(fit.stepwise$coefficients)
aic <- extractAIC(fit.stepwise)[2]
SSE <- sum(fit.stepwise$residuals^2)
MSE_F <- anova(fit.full)["Residuals", "Mean Sq"]

data.frame(R2 = model$r.squared, 
           R2_adj = model$adj.r.squared,
           C = SSE / MSE_F + 2*p_prime - n,
           AIC = aic,
           BIC = aic + log(n)*p_prime - 2*p_prime,
           PRESS = PRESS(fit.stepwise))
```

Note the poor results overall on these metrics, however, to be sure, we will see if it is validated. We now head to find the MSPE and see if it is close to the MSE.

```{r}
pred.test <- predict(fit.stepwise, brownfat.test)
delta.test <- brownfat.test$Total_vol - pred.test
n.star <- nrow(brownfat.test)
MSPE <- sum((delta.test)^2) / n.star
paste("The MSPE is :", MSPE)

MSE_R <- anova(fit.stepwise)["Residuals", "Mean Sq"]
paste("The MSE is :", MSE_R)
```
Observe that the MSPE is almost double the MSE, this is not good as this suggests overfitting.

Perhaps an interaction/quadratic model would be better, we once again perform step-wise regression on the training data.

```{r}
quad.fit.full <- lm(Total_vol ~ (.)^2, data=brownfat.train)
quad.fit.stepwise <- stats::step(fit.simple, 
                          scope=list(upper=quad.fit.full, lower=fit.simple),
                          direction="both", trace=0)
summary(quad.fit.stepwise)
extractAIC(quad.fit.stepwise)
```
We'll see if we are able to validate the model.

```{r}
pred.test <- predict(quad.fit.stepwise, brownfat.test)
delta.test <- brownfat.test$Total_vol - pred.test
n.star <- nrow(brownfat.test)
MSPE <- sum((delta.test)^2) / n.star
paste("The MSPE is :", MSPE)

MSE_R <- anova(quad.fit.stepwise)["Residuals", "Mean Sq"]
paste("The MSE is :", MSE_R)
```
This is still not good, we'll try tinkering around with the final interaction model.

```{r}
model_final <- lm(Total_vol ~  `7D_Temp` + `3D_Temp` + `1M_Temp` + 
    Ext_Temp + Sex + Weigth + Cancer_Status + Age:`7D_Temp` + 
    Age:`3D_Temp` + Age:Ext_Temp + Age:`1M_Temp` + Age:Sex + 
    `7D_Temp`:Weigth + `3D_Temp`:Weigth + Ext_Temp:Weigth + Sex:Weigth + 
    `7D_Temp`:Cancer_Status + `3D_Temp`:Cancer_Status, 
    data = brownfat.train)

# check VIF for multicollinearity
vif(model_final)
```
VIF values are very high for many predictors, consider centering the data.

```{r}
brownfat.train.centered <- brownfat.train %>%
  mutate(`7D_Temp` = `7D_Temp` - mean(`7D_Temp`),
         `3D_Temp` = `3D_Temp` - mean(`3D_Temp`),
         `1M_Temp` = `1M_Temp` - mean(`1M_Temp`),
         Ext_Temp = Ext_Temp - mean(Ext_Temp),
         Weigth = Weigth - mean(Weigth),
         Age = Age - mean(Age))

model_final_centered <- lm(Total_vol ~  `7D_Temp` + `3D_Temp` + `1M_Temp` + 
    Ext_Temp + Sex + Weigth + Cancer_Status + Age:`7D_Temp` + 
    Age:`3D_Temp` + Age:Ext_Temp + Age:`1M_Temp` + Age:Sex + 
    `7D_Temp`:Weigth + `3D_Temp`:Weigth + Ext_Temp:Weigth + Sex:Weigth + 
    `7D_Temp`:Cancer_Status + `3D_Temp`:Cancer_Status, 
    data = brownfat.train.centered)

vif(model_final_centered)
```
We will remove all predictors w/ VIF > 10.

```{r}
model_final_centered <- lm(Total_vol ~ `7D_Temp` + `1M_Temp` + Ext_Temp + Sex + Weigth + Cancer_Status + Age:Ext_Temp + Age:`1M_Temp` + Age:Sex + `7D_Temp`:Weigth + Ext_Temp:Weigth + Sex:Weigth + `7D_Temp`:Age , 
    data = brownfat.train.centered)
summary(model_final_centered)

vif(model_final_centered)
```

Perhaps our poor performance are due to outliers, we perform an analysis for outliers on the non-interaction stepwise model first.

```{r}
fit.stepwise.rstandard <- rstandard(fit.stepwise)
fit.stepwise.rstudent <- rstudent(fit.stepwise)
fit.stepwise.inf <- influence.measures(fit.stepwise)
data.frame(fit.stepwise.rstandard, fit.stepwise.rstudent)
fit.stepwise.inf
```

Some key graphs for diagnosis:

```{r}
library(ggpubr)
library(olsrr)
ols_plot_added_variable(fit.stepwise)
ols_plot_cooksd_chart(fit.stepwise)
ols_plot_dfbetas(fit.stepwise)
ols_plot_dffits(fit.stepwise)
ols_plot_resid_lev(fit.stepwise)
ols_plot_resid_stud_fit(fit.stepwise)
```
We'll try to remove some observations:

```{r}
inf_data <- c()

for (i in 1:nrow(brownfat.train)) {
  if (sum(fit.stepwise.inf$is.inf[i, ]) > 0) {
    inf_data <- c(inf_data, i)
  }
}

brownfat.train_no.inf <- brownfat.train.centered[-inf_data,]

fit.full_no.inf <- lm(Total_vol ~ (.)^2, data=brownfat.train_no.inf)
fit.simple_no.inf <- lm(Total_vol ~ 1, data=brownfat.train_no.inf)
fit.stepwise_no.inf <- stats::step(fit.simple_no.inf, 
                            scope=list(upper=fit.full_no.inf, lower=fit.simple_no.inf),
                            direction="both", trace=0)
summary(fit.stepwise_no.inf)

brownfat.test.centered <- brownfat.test %>%
  mutate(`7D_Temp` = `7D_Temp` - mean(`7D_Temp`),
         `3D_Temp` = `3D_Temp` - mean(`3D_Temp`),
         `1M_Temp` = `1M_Temp` - mean(`1M_Temp`),
         Ext_Temp = Ext_Temp - mean(Ext_Temp),
         Weigth = Weigth - mean(Weigth),
         Age = Age - mean(Age))

pred.test <- predict(fit.stepwise_no.inf, brownfat.test.centered)
delta.test <- brownfat.test.centered$Total_vol - pred.test
n.star <- nrow(brownfat.test.centered)
MSPE <- sum((delta.test)^2) / n.star
paste("The MSPE is :", MSPE)

MSE_R <- anova(fit.stepwise_no.inf)["Residuals", "Mean Sq"]
paste("The MSE is :", MSE_R)
```

