---
title: "brownfat"
output: html_document
---

```{r}
library(readxl)
library(dplyr)
```

Read the file:

```{r}
# the excel sheet represents NA values by "NA"
brownfat <- read_excel("./description/BrownFat.xls", na = "NA")
nrow(brownfat)
```

Check if there's any NA values:

```{r}
x <- colSums(is.na(brownfat)) # 
x[x > 0]
```

3 variables has NA values detected: Cancer_Status, Cancer_Type, and TSH. Data cleaning needed.

Notice that $4425$ out of $n=4842$ observations had no data on their `TSH`, as this ratio is too large in order for us to confidently assign the most-probable values, we will choose to exclude the variable `TSH` altogether.

```{r}
brownfat_cleaned_data <- brownfat %>% dplyr::select(-c("TSH"))
```

There are observations where both the `Cancer_Status` and `Cancer_Type` is set to NA, as we don't have domain knowledge to assign appropriate values nor is it the main focus of this research, we will simply exclude these observations.

```{r}
# determine how many obs. display such behaviour
x <- sum(is.na(brownfat$Cancer_Status) & is.na(brownfat$Cancer_Type))
paste("No. of observations w/ Cancer_Status == Cancer_Type == NA is:", x)

# exclude these obs.
brownfat_cleaned_data <- brownfat_cleaned_data %>% 
  filter(!(is.na(Cancer_Status) & is.na(Cancer_Type)))
```

Observe that since the remaining $369  - 250 = 119$ observations still having `Cancer_Type == NA` also have that `Cancer_Status == 0`, meaning they do have cancer (thus setting `Cancer_Type` to $0$ is not a valid option) and hence we can either assign values to these missing values or once again, simply remove them.

-   Option 1: We calculate the estimate probability of each category (other than $0$) based on their frequency in the given data, and then assign `NA` values using our new probability measure.

```{r}
set.seed("14")

# calculate the estimated prob. of each category (except 0, and NAs)
cancer_status_category_prob <- brownfat_cleaned_data %>%
  filter(!is.na(Cancer_Type) & Cancer_Type != 0) %>%
  count(Cancer_Type) %>% 
  mutate(probability = n / sum(n))

# function to re-assign those w/ NA values
assign_cancer_type <- function(x) {
  if (is.na(x)) {
    sample(cancer_status_category_prob$Cancer_Type, 1, 
           prob = cancer_status_category_prob$probability)
  } else {
    x
  }
}


# re-assign those w/ Cancer_Type == NA
brownfat_cleaned_data_v1 <- brownfat_cleaned_data
brownfat_cleaned_data_v1$Cancer_Type <- sapply(brownfat_cleaned_data$Cancer_Type,
                                   assign_cancer_type)
```

Why may this method be problematic? =\> We've only taking into the account the frequencies of each of these types of cancer when in reality, a multitude of other factors affect the diagnosis of single patient. (We may consider to improve this later on by also creating a prediction model)

-   Option 2: To avoid potential hazardous assumptions, we may opt to exclude these `NA` values altogether:

```{r}
brownfat_cleaned_data_v2 <- brownfat_cleaned_data %>%
  filter(!is.na(Cancer_Type))
```

## CROSS VALIDATION

Split into training and testing set.

```{r}
# convert categorical vars into factors, and rename some vars.
brownfat_cleaned_data_v2 <- brownfat_cleaned_data_v2 %>%
  mutate(Sex = as.factor(Sex),
         Diabetes = as.factor(Diabetes),
         Month = as.factor(Month),
         Season = as.factor(Season),
         Cancer_Status = as.factor(Cancer_Status),
         Cancer_Type = as.factor(Cancer_Type)) %>%
  rename(Temp_2D = `2D_Temp`,
         Temp_3D = `3D_Temp`,
         Temp_7D = `7D_Temp`,
         Temp_1M = `1M_Temp`)

# split into train and test set
set.seed(500)
samp <- sample(1:nrow(brownfat_cleaned_data_v2),
               size = floor(0.7*nrow(brownfat_cleaned_data_v2)),
               replace=FALSE)
train <- brownfat_cleaned_data_v2[samp,]
test <- brownfat_cleaned_data_v2[-samp,]
```

Libraries needed:
```{r}
require(flexplot)
require(tidyverse)
require(pscl)
```



## ZERO INFLATED LOGNORMAL MODEL

```{r}
library(glmmTMB)

# Note we exclude multi-class categorical variables to avoid non-convergence
zilgnorm <- glmmTMB(Total_vol ~ Age + Sex + Ext_Temp + Temp_3D + Temp_2D + 
                       Temp_1M + Diabetes + Weigth + LBW,
                     ziformula = ~ Age + Sex + Ext_Temp + Temp_3D + Temp_2D + 
                       Temp_1M + Diabetes + Weigth + LBW,
                     family = lognormal(link = "log"),
                     data = train,
                     na.action = "na.fail")

#zig_model.step <- MASS::stepAIC(zig_model, direction="both")

```

```{r}
# this is the model after stepwise reg. based on AIC
zilgnorm.step <- glmmTMB(Total_vol ~ Age + Diabetes + Temp_3D + Weigth,
                         ziformula = ~ Age + Sex + Ext_Temp + Temp_3D + 
                           Temp_2D + Temp_1M + Diabetes + Weigth + LBW,
                       family = lognormal(link="log"),
                       data=train,
                       na.action="na.fail")

#optimize the covariates based on AIC
#library(MuMIn)
#model.dredge <- MuMIn::dredge(simpler_zip, trace=2)

# model after dredge, note that the current model is indeed the best model (i.e. no change)
# but choose best 4th model w/ AIC = 3386.2 (compare to best model w/ AIC = 3385.3)
# as deltaAIC is not large, & the 4th best model only has 2 covariates, we choose this to simplify complexity
zilgnorm.dredged <- glmmTMB(Total_vol ~ Age  + Temp_3D,
                            ziformula = ~ Age + Diabetes + Ext_Temp + LBW + 
                              Sex + Temp_1M + Temp_2D + Temp_3D + Weigth,
                            dispformula = ~ 1, 
                            data=train,
                            family=lognormal(link="log"),
                            na.action = "na.fail")
```


Now let's do predictions & its AIC:

```{r}
pred.test <- predict(zilgnorm.dredged, newdata=test, type="response")
actual.test <- test$Total_vol
MSPE <- sum((actual.test-pred.test)^2) / nrow(test)
MSPE

pred.train <- predict(zilgnorm.dredged, type="response")
actual.train <- train$Total_vol
MSE <- sum((actual.train-pred.train)^2) / (nrow(train) - 14)
MSE


extractAIC(final_zip)
```

Note the MSE and MSPE are relatively similar to the linear regression model, however, do note the much lower AIC values. While it is important to note that AIC values are not typically comparable between different types of models (in this case, lm vs. zero inflated), a large difference of AIC can indicate that the zero inflated model may be more fitted and likely to accurately predict the response variable, i.e. the total volume of brown fat.



